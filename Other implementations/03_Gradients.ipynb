{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNBigt4Op3XmWM8+8VSG6aM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"id":"aWcQeFNTZx_1","executionInfo":{"status":"ok","timestamp":1687443292323,"user_tz":240,"elapsed":5,"user":{"displayName":"HANIA MENNAD","userId":"13289610165043301578"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss"]},{"cell_type":"code","source":["#Model creation and running a forward pass : Forward propagation\n","sample = torch.randn(16)\n","\n","model = nn.Sequential(\n","    nn.Linear(16, 8),\n","    nn.Linear(8, 4),\n","    nn.Linear(4, 2)\n",")\n","\n","prediction = model(sample)\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ou6ARoKXbAJ8","executionInfo":{"status":"ok","timestamp":1687443294695,"user_tz":240,"elapsed":244,"user":{"displayName":"HANIA MENNAD","userId":"13289610165043301578"}},"outputId":"c99e730d-1209-461f-965c-a35173298356"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.1948, -0.6310], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":["#Calculation the loss and gradients\n","\n","criterion = CrossEntropyLoss()\n","loss = criterion(prediction.double(), torch.tensor([1, 0]).double())\n","\n","loss.backward()"],"metadata":{"id":"aZsMMamrbybJ","executionInfo":{"status":"ok","timestamp":1687443298493,"user_tz":240,"elapsed":232,"user":{"displayName":"HANIA MENNAD","userId":"13289610165043301578"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#Accessing each layer's gradients\n","\n","print(model[0].weight.grad,model[0].bias.grad)\n","print(model[1].weight.grad,model[1].bias.grad)\n","print(model[2].weight.grad,model[2].bias.grad)"],"metadata":{"id":"CIwguHuqdLTS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We use Gradient Descent for non-convex functions\n","\n","The  most common optimizer is stochastic gradient descent (SGD)"],"metadata":{"id":"LusVrO60eC1w"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","#create the optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.001)"],"metadata":{"id":"0Izf_O3meZ0v","executionInfo":{"status":"ok","timestamp":1687443655436,"user_tz":240,"elapsed":309,"user":{"displayName":"HANIA MENNAD","userId":"13289610165043301578"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["The optimizer take care of updating the weights of the model after calculating local gradients"],"metadata":{"id":"pyrQ_1Phe17m"}},{"cell_type":"code","source":["optimizer.step()"],"metadata":{"id":"gE6hNJSVfHQj","executionInfo":{"status":"ok","timestamp":1687447580665,"user_tz":240,"elapsed":286,"user":{"displayName":"HANIA MENNAD","userId":"13289610165043301578"}}},"execution_count":22,"outputs":[]}]}